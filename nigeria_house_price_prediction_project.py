# -*- coding: utf-8 -*-
"""Nigeria house price prediction project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15W4dkAKa3KWxp7VIIxSsIY5d0_5T71Fl
"""

import numpy as np
import pandas as pd
import plotly.express as px
pd.set_option('display.max_rows', 100)
pd.set_option('display.max_columns',20000)

dataset=pd.read_csv(r'C:\Users\CODED\OneDrive\Documents\housepredictionproject\nigeria_houses_data.csv')



dataset.head()

dataset.shape

dataset.info()

dataset.isnull().sum()



dataset.describe(include='all')

dataset.columns

dataset.duplicated().sum()

#dataset = dataset.drop_duplicates()

dataset.tail(20)

dataset.head(6)





dataset['duplex_apartment'] = dataset['title'].apply(lambda x: 'Duplex' if 'Duplex' in x and 'Semi Detached Duplex' and'Terraced Duplexes' in x else 'Not Duplex')
dataset['bungalow_apartment'] = dataset['title'].apply(lambda x: 'Bungalow' if 'Bungalow' in x else 'Storey-Building')
dataset['flat_apartment']=dataset['title'].apply(lambda x:'Flat' if 'Flats' in x else 'Not Flat'  )

dataset['state'].unique()

west_states = ['Lagos', 'Ogun', 'Oyo', 'Osun', 'Kwara', 'Ekiti']
south_states=['Edo','Rivers','Delta','Akwa Ibom','Cross River','Bayelsa']
East_states=['Imo', 'Anambara','Enugu','Abia']

def assign_region(state):
    if state in west_states:
        return 'West'
    elif state in south_states:
        return 'South'
    elif state in East_states:
        return 'East'
    else:
        return 'North'

dataset.groupby('state')['price'].max()

pd.set_option('display.max_row',2000)

dataset['region'] = dataset['state'].apply(lambda x : assign_region(x))

def assign_category(row):
  if row['bedrooms'] in [9.0,8.0,7.0,6.0] and row['bathrooms'] in [9.0,8.0,7.0,6.0] and row['toilets'] in [9.0,8.0,7.0,6.0]:
   return 'Luxury_apartments'
  elif row['bedrooms'] in [5.0,4.0] and row['bathrooms'] in [5.0,4.0] and row['toilets'] in [5.0,4.0]:
    return 'Executive_apartment'
  else:
    return 'comfort_apartment'

dataset['Apartment_type']=dataset.apply(assign_category,axis=1)

dataset.head()

dataset['title'].unique()

dataset.duplicated().sum()

px.pie(dataset, names='region', title='Distribution of Houses by Region',width = 500)

#!pip install ydata-profiling

#from ydata_profiling import ProfileReport

#report=ProfileReport(dataset)

#report

#report.to_file('ZeeTheTechie House Price Prediction project')

dataset.head(5)

dataset['price'].max()

from scipy import stats

dataset = dataset[dataset['price'] < 100_000_000]

dataset=dataset[(np.abs(stats.zscore(dataset['price']))<3)]

dataset.drop_duplicates(inplace=True)

dataset.head(5)

px.box(dataset,x='price',title='price distribution')

px.scatter(dataset,x='price', y='Apartment_type')

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import HistGradientBoostingRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import BaggingRegressor

dataset.select_dtypes('object').columns
print(dataset.select_dtypes('number').columns.tolist())
import pickle

title_encoder=LabelEncoder()
town_encoder = LabelEncoder()
state_encoder=LabelEncoder()
region_encoder=LabelEncoder()
Apartment_type_encoder=LabelEncoder()
duplex_encoder = LabelEncoder()
bungalow_encoder = LabelEncoder()
flat_encoder = LabelEncoder()

dataset['title']=title_encoder.fit_transform(dataset['title'])
with open(r'C:\Users\CODED\OneDrive\Documents\housepredictionproject\encoders\title.pkl','wb')as file:
  pickle.dump(title_encoder,file)

dataset['flat_apartment']=flat_encoder.fit_transform(dataset['flat_apartment'])
with open(r'C:\Users\CODED\OneDrive\Documents\housepredictionproject\encoders\flat.pkl','wb')as file:
  pickle.dump(flat_encoder,file)

dataset['bungalow_apartment']=bungalow_encoder.fit_transform(dataset['bungalow_apartment'])
with open(r'C:\Users\CODED\OneDrive\Documents\housepredictionproject\encoders\bungalow.pkl','wb')as file:
  pickle.dump(bungalow_encoder,file)

dataset['duplex_apartment']=duplex_encoder.fit_transform(dataset['duplex_apartment'])
with open(r'C:\Users\CODED\OneDrive\Documents\housepredictionproject\encoders\duplex.pkl','wb')as file:
  pickle.dump(duplex_encoder,file)

dataset['town'] = town_encoder.fit_transform(dataset['town'])
with open(r'C:\Users\CODED\OneDrive\Documents\housepredictionproject\encoders\town.pkl','wb')as file:
  pickle.dump(town_encoder,file)

dataset['state']=state_encoder.fit_transform(dataset['state'])
with open(r'C:\Users\CODED\OneDrive\Documents\housepredictionproject\encoders\state.pkl','wb')as file:
  pickle.dump(state_encoder,file)

dataset[ 'region']=region_encoder.fit_transform(dataset['region'])
with open (r'C:\Users\CODED\OneDrive\Documents\housepredictionproject\encoders\region.pkl','wb')as file:
  pickle.dump(region_encoder,file)

dataset['Apartment_type']=Apartment_type_encoder.fit_transform(dataset['Apartment_type'])
with open(r'C:\Users\CODED\OneDrive\Documents\housepredictionproject\encoders\Apartment_type.pkl','wb')as file:
  pickle.dump(Apartment_type_encoder,file)

dataset.info()

X=dataset.drop(columns=['price'])
y=dataset['price']

x_train,x_test,y_train,y_test= train_test_split(X,y,random_state=42,test_size=0.20)

print(f'x_train shape:{x_train.shape}')
print(f'x_test shape:{x_train.shape}')
print(f'y_train shape:{y_train.shape}')
print(f'y_test shape:{y_test.shape}')

Scaler=StandardScaler()

Scaler.fit_transform(x_train)

Scaler.transform(x_test)

dataset.head(1)

linear_model=LinearRegression()

linear_model.fit(x_train,y_train)

ypred=linear_model.predict(x_test)

ypred

mse=mean_squared_error(y_test,ypred)

mse

from math import sqrt

sqrt(mean_squared_error(y_test,ypred))

r2_score(y_test,ypred)

forest_model=RandomForestRegressor()

forest_model.fit(x_train,y_train)

ypred=forest_model.predict(x_test)

mse=mean_squared_error(y_test,ypred)

sqrt(mean_squared_error(y_test,ypred))

mse

r2_score(y_test,ypred)

tree_model=DecisionTreeRegressor()

tree_model.fit(x_train,y_train)

y_pred=tree_model.predict(x_test)

mean_squared_error(y_test,y_pred)

sqrt(mean_squared_error(y_test,ypred))

r2_score(y_test,y_pred)

sv=SVR()

sv.fit(x_train,y_train)

y_pred=sv.predict(x_test)

mean_squared_error(y_test,y_pred)

sqrt(mean_squared_error(y_test,ypred))

r2_score(y_test,y_pred)

knn=KNeighborsRegressor()

knn.fit(x_train,y_train)

from math import sqrt

y_pred=knn.predict(x_test)

mean_squared_error(y_test,y_pred)

sqrt(mean_squared_error(y_test,y_pred))

r2_score(y_test,y_pred)

gbr_model= HistGradientBoostingRegressor()

gbr_model.fit(x_train,y_train)

y_pred=gbr_model.predict(x_test)

mean_squared_error(y_test,y_pred)

sqrt(mean_squared_error(y_test,y_pred))

r2_score(y_test,y_pred)

with open('gbr_model.pkl','wb')as file:
  pickle.dump(gbr_model,file)

with open('scalar.pkl','wb')as file:
  pickle.dump(Scaler,file)

print('successfull')
print(X.columns.tolist())
